{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Pose Landmarks Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use MediaPipe Tasks Python API to detect pose landmarks from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\moham\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\moham\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install -q --user mediapipe==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model bundle. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker#models) for more information about this model bundle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [],
      "source": [
        "#@markdown To better demonstrate the Pose Landmarker API, we have created a set of visualization tools that will be used in this colab. These will draw the landmarks on a detect person, as well as the expected connections between those markers.\n",
        "\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected poses to visualize.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # Draw the pose landmarks.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image,\n",
        "      pose_landmarks_proto,\n",
        "      solutions.pose.POSE_CONNECTIONS,\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "To demonstrate the Pose Landmarker API, you can download a sample image using the follow code. The image is from [Pixabay](https://pixabay.com/photos/girl-woman-fitness-beautiful-smile-4051811/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mwget -q -O image.jpg https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpatches\u001b[39;00m \u001b[39mimport\u001b[39;00m cv2_imshow\n\u001b[0;32m      6\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mimage.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m cv2_imshow(img)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!wget -q -O image.jpg https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"image.jpg\")\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded:\n",
        "#   content = uploaded[filename]\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(content)\n",
        "\n",
        "# if len(uploaded.keys()):\n",
        "#   IMAGE_FILE = next(iter(uploaded))\n",
        "#   print('Uploaded file:', IMAGE_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "The final step is to run pose landmark detection on your selected image. This involves creating your PoseLandmarker object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/python) to learn more about configuration options that this solution supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Unable to open file at c:\\Users\\moham\\Dropbox\\Python\\Projects\\PyLearnImageProcessing\\PyLearnIPSupplementaryTopics\\pose_landmarker.task",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m base_options \u001b[39m=\u001b[39m python\u001b[39m.\u001b[39mBaseOptions(model_asset_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpose_landmarker.task\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m options \u001b[39m=\u001b[39m vision\u001b[39m.\u001b[39mPoseLandmarkerOptions(\n\u001b[0;32m      9\u001b[0m     base_options\u001b[39m=\u001b[39mbase_options,\n\u001b[0;32m     10\u001b[0m     output_segmentation_masks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m detector \u001b[39m=\u001b[39m vision\u001b[39m.\u001b[39;49mPoseLandmarker\u001b[39m.\u001b[39;49mcreate_from_options(options)\n\u001b[0;32m     13\u001b[0m \u001b[39m# STEP 3: Load the input image.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m image \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mcreate_from_file(\u001b[39m\"\u001b[39m\u001b[39mimage.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mediapipe\\tasks\\python\\vision\\pose_landmarker.py:319\u001b[0m, in \u001b[0;36mPoseLandmarker.create_from_options\u001b[1;34m(cls, options)\u001b[0m\n\u001b[0;32m    306\u001b[0m   output_streams\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    307\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([_SEGMENTATION_MASK_TAG, _SEGMENTATION_MASK_STREAM_NAME])\n\u001b[0;32m    308\u001b[0m   )\n\u001b[0;32m    310\u001b[0m task_info \u001b[39m=\u001b[39m _TaskInfo(\n\u001b[0;32m    311\u001b[0m     task_graph\u001b[39m=\u001b[39m_TASK_GRAPH_NAME,\n\u001b[0;32m    312\u001b[0m     input_streams\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m     task_options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m    318\u001b[0m )\n\u001b[1;32m--> 319\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    320\u001b[0m     task_info\u001b[39m.\u001b[39;49mgenerate_graph_config(\n\u001b[0;32m    321\u001b[0m         enable_flow_limiting\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mrunning_mode\n\u001b[0;32m    322\u001b[0m         \u001b[39m==\u001b[39;49m _RunningMode\u001b[39m.\u001b[39;49mLIVE_STREAM\n\u001b[0;32m    323\u001b[0m     ),\n\u001b[0;32m    324\u001b[0m     options\u001b[39m.\u001b[39;49mrunning_mode,\n\u001b[0;32m    325\u001b[0m     packets_callback \u001b[39mif\u001b[39;49;00m options\u001b[39m.\u001b[39;49mresult_callback \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    326\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mediapipe\\tasks\\python\\vision\\core\\base_vision_task_api.py:70\u001b[0m, in \u001b[0;36mBaseVisionTaskApi.__init__\u001b[1;34m(self, graph_config, running_mode, packet_callback)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39melif\u001b[39;00m packet_callback:\n\u001b[0;32m     66\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThe vision task is in image or video mode, a user-defined result \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     68\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mcallback should not be provided.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     69\u001b[0m   )\n\u001b[1;32m---> 70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_runner \u001b[39m=\u001b[39m _TaskRunner\u001b[39m.\u001b[39;49mcreate(graph_config, packet_callback)\n\u001b[0;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_running_mode \u001b[39m=\u001b[39m running_mode\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Unable to open file at c:\\Users\\moham\\Dropbox\\Python\\Projects\\PyLearnImageProcessing\\PyLearnIPSupplementaryTopics\\pose_landmarker.task"
          ]
        }
      ],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an PoseLandmarker object.\n",
        "base_options = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
        "options = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options,\n",
        "    output_segmentation_masks=True)\n",
        "detector = vision.PoseLandmarker.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(\"image.jpg\")\n",
        "\n",
        "# STEP 4: Detect pose landmarks from the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BwzFvaxwtPX"
      },
      "source": [
        "Visualize the pose segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jAIFzw9M3JJ"
      },
      "outputs": [],
      "source": [
        "segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
        "visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
        "cv2_imshow(visualized_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QipRi2ozw7cg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
